#!/usr/bin/env groovy
//
// The main Jenkinsfile for IDMP, defining the Build/Publish/Test/Deploy process that is
// executed for each push into the repository.
//
// Note that this file is in the so called "Declarative Pipeline" syntax
//
// See https://jenkins.io/doc/book/pipeline/jenkinsfile/
//
// Required plugins:
// - [Pipeline: SCM Step](https://plugins.jenkins.io/workflow-scm-step/) = workflow-scm-step
// - [Pipeline Utility Steps](https://plugins.jenkins.io/pipeline-utility-steps/) = pipeline-utility-steps

import groovy.json.JsonSlurper

//String[] derivedProducts = ['datadictionary', 'index', 'vocabulary']
String[] derivedProducts = ['datadictionary', 'vocabulary']

env.ONTPUB_FAMILY='idmp'
env.ONTPUB_SPEC_HOST='spec.pistoiaalliance.org'
env.DEV_SPEC='AboutIDMPDev-ReferenceIndividuals.rdf'
env.PROD_SPEC='AboutIDMPProd-ReferenceIndividuals.rdf'
env.HYGIENE_TEST_PARAMETER_VALUE='idmp'
env.HYGIENE_WARN_INCONSISTENCY_SPEC_FILE_NAME="${env.DEV_SPEC}"
env.HYGIENE_ERROR_INCONSISTENCY_SPEC_FILE_NAME="${env.PROD_SPEC}"
env.ONTPUB_MERGED_INFIX="-Merged"
env.ONTPUB_IS_DARK_MODE='1'
env.ONTPUB_IMAGE='edmcouncil/ontology-publisher:build-dev'
env.LC_ALL='en_US.UTF-8'
env.LANG='en_US.UTF-8'
env.LANGUAGE='en_US.UTF-8'
env.NGINX_SPEC_ROOT="/opt/dev.${env.ONTPUB_SPEC_HOST}"

properties([
  buildDiscarder(
          logRotator(artifactDaysToKeepStr: '', artifactNumToKeepStr: '', daysToKeepStr: '', numToKeepStr: '30')
  ),
  //
  // We let each stage running on each jenkins slave / agent decide what to check out or not
  //
//  skipDefaultCheckout(),
  //
  // Skip stages once the build status has gone to UNSTABLE.
  //
//  skipStagesAfterUnstable(),
  //
  // There must be SOME limit, if it hangs or whatever then that's a bug and therefore cancel the job.
  //
//  timeout(time: 23, unit: 'HOURS'),
  //
  // Prepend all console output generated by the Pipeline run with the time at which the line was emitted
  //
  //timestamps()
//  ansiColor('xterm')
])

//
// Return a stage object that will get executed in the appropriate ontology-publisher container
//
def runInOntologyPublisherContainer(Map config, Closure body) {

  assert config.shortStageName != null
  assert config.longStageName != null
  assert body != null

  return {
    stage(config.longStageName) {

      echo "runInOntologyPublisherContainer shortStageName:${config.shortStageName}, longStageName:${config.longStageName}"

      def containerName = "${env.JOB_NAME}-${env.NODE_NAME}-${env.EXECUTOR_NUMBER}-${config.shortStageName}".replaceAll(/[^a-zA-Z0-9_.-]/, "_")

      node('docker') {
        echo "Running in stage \"${config.longStageName}\" now"
        sh "rm -rf input"
        unstash "input"
        sh "rm -rf output"
        if (config.unstashOutputDirs) {
          config.unstashOutputDirs.each { outputDir ->
            unstash "output-${outputDir}"
          }
        }
        if (("${config.shortStageName}" != "ontology") && ("${config.shortStageName}" != "hygiene")) {
          unstash "output-ontology"
        }
        sh "install -d output tmp"
        echo "Launching docker container ${containerName}:"
        try {
          def dockerImage = docker.image(env.ONTPUB_IMAGE)
          dockerImage.pull()
          dockerImage.inside("""
            --read-only
            --name ${containerName}
            --mount type=bind,source=${env.WORKSPACE}/input,target=/input,readonly,consistency=cached
            --mount type=bind,source=${env.WORKSPACE}/output,target=/output,consistency=delegated
            --mount type=bind,source=${env.WORKSPACE}/tmp,target=/var/tmp,consistency=delegated
          """) {
            echo "Running in docker container ${containerName}"
            //
            // Now execute whatever you had in the closure
            //
            body()
          }
        } catch (e) {
          currentBuild.result = "FAILURE"
          echo "Failed stage \"${config.longStageName}\": ${e}"
          throw e
        } finally {
          echo "Finished stage \"${config.longStageName}\" in docker container ${containerName}"
          def json = null
          def files = findFiles(glob: "output/${env.ONTPUB_FAMILY}/**/consistency-check.json")
          if (files.length > 0) {
            def fileContent = readFile "${files[0].path}"
            json = new JsonSlurper().parseText(fileContent)
          }
          if (config.archiveArtifacts == true) {
            archiveArtifacts artifacts: "output/${env.ONTPUB_FAMILY}/${config.shortStageName}/**/*.log,output/${env.ONTPUB_FAMILY}/${config.shortStageName}/**/consistency-check.json", fingerprint: true
          }
          deleteDir()
          dir("${workspace}@tmp") {
            deleteDir()
          }
          if ("${config.shortStageName}" == "hygiene") {
            for (spec_file in json?.warning?.keySet()) {
              def stat = json.warning."${spec_file}"
              catchError(buildResult: null, stageResult: 'FAILURE') {
                if (stat.containsKey('error')) {
                  error "${spec_file}: error '${stat.'error'}'"
                } else if (stat.containsKey('timeout')) {
                  error "${spec_file}: timeout after '${stat.'timeout'}'"
                } else if ((stat.containsKey('output')) && (stat.'output'.containsKey('consistent')) && !(stat.'output'.'consistent')) {
                  error "${spec_file}: is inconsistent"
                }
              }
            }
            for (spec_file in json?.error?.keySet()) {
              def stat = json.error."${spec_file}"
              if (stat.containsKey('error')) {
                error "${spec_file}: error '${stat.'error'}'"
              } else if (stat.containsKey('timeout')) {
                error "${spec_file}: timeout after '${stat.'timeout'}'"
              } else if ((stat.containsKey('output')) && (stat.'output'.containsKey('consistent')) && !(stat.'output'.'consistent')) {
                error "${spec_file}: is inconsistent"
              }
            }
          }
        }
      }
    }
  }
}
//
// Return the stage object that runs the hygiene tests
//
def hygiene() {

  return runInOntologyPublisherContainer(
    shortStageName: 'hygiene',
    longStageName: 'Hygiene Tests',
    archiveArtifacts: true
  ) {
    sh "/publisher/publish.sh hygiene"
    stash name: "output-hygiene", includes: "output/${env.ONTPUB_FAMILY}/hygiene/**", excludes: "output/${env.ONTPUB_FAMILY}/hygiene/**/*.log"
  }
}

//
// Return the stage that produces the output of the given product
//
def product(String product) {

  return runInOntologyPublisherContainer(
    shortStageName: product,
    longStageName: "Build ${product.capitalize()}",
    archiveArtifacts: true
  ) {
    sh "/publisher/publish.sh ${product}"
    stash name: "output-${product}", includes: "output/${env.ONTPUB_FAMILY}/${product}/**", excludes: "output/${env.ONTPUB_FAMILY}/${product}/**/*.log"
  }
}

//
// Return the stage object that runs the publish action
//
def publish(String[] derivedProducts) {

  return runInOntologyPublisherContainer(
    shortStageName: 'publish',
    longStageName: 'Build Final Content',
    unstashOutputDirs: (derivedProducts + 'hygiene')
  ) {
    //
    // Now after all the above is done, make sure we run the final
    // publish step which zips it all up into the output directory
    //
    sh "/publisher/publish.sh publish"
    //
    // Stash the artifacts generated by the publish command
    //
    dir('output') {
      sh "find . -type f -name *.log -delete"
      tar file: "publishable-output.tar.gz", compress: true, overwrite: true
      stash name: "publishable-output", includes: "publishable-output.tar.gz"
    }
  }
}

node {
  ansiColor('xterm') {
    stage('Setup') {
      dir("input/${env.ONTPUB_FAMILY}") {
        checkout scm
      }
      stash name: "input", useDefaultExcludes: false
      deleteDir()
      dir("${workspace}@tmp") {
        deleteDir()
      }
    }

    hygiene().call()

    product('ontology').call()

    stage('Build Derived Products') {
      def parallelStages = derivedProducts.collectEntries { prod ->
        [ "Build ${prod}" : product(prod)]
      }
      parallel(parallelStages)
    }

    publish(derivedProducts).call()

    //
    // Run the publish on the master jenkins agent by just copying all the generated artifacts right into the workspace
    // on master and let NGINX just serve it from there.
    //
    // This workspace will never be "wiped" so it contains all the older versions as well, wiping this workspace
    // will be bad because we would lose all previously published versions
    //
    stage('Publish') {
      node('build-dev') {
        // setting variables
        script {
	  // Replace all slashes in a branch name with dashes so that we don't mess up the URLs for the ontologies
	  // ... make it all lower case
          BRANCH = sh(returnStdout: true, script: 'if [ -n "${TAG_NAME}" ] ; then echo "${TAG_NAME//\\//-}" | cut -d_ -f 1 ; else echo "${BRANCH_NAME//\\//-}" ; fi').trim().toLowerCase()
          TAG    = sh(returnStdout: true, script: 'if [ -n "${TAG_NAME}" ] ; then echo "${TAG_NAME}" | cut -d_ -f 2 ; else echo "latest" ; fi').trim()
        }
        try {
          echo "Unstashing the publishable-output"
          unstash 'publishable-output'
          echo "Delete product destination directory: \"${env.ONTPUB_FAMILY}/ontology/${BRANCH}/${TAG}\""
          dir("${NGINX_SPEC_ROOT}/${env.ONTPUB_FAMILY}/ontology/${BRANCH}/${TAG}") {
            deleteDir()
          }
          derivedProducts.each { productName ->
            echo "Delete product destination directory: \"${env.ONTPUB_FAMILY}/${productName}/${BRANCH}/${TAG}\""
            dir("${NGINX_SPEC_ROOT}/${env.ONTPUB_FAMILY}/${productName}/${BRANCH}/${TAG}") {
              deleteDir()
            }
          }
          echo "untar 'publishable-output.tar.gz' to ${NGINX_SPEC_ROOT}"
          untar file: "publishable-output.tar.gz", dir: "${NGINX_SPEC_ROOT}"
        } catch (e) {
          currentBuild.result = "FAILURE"
          echo "Failed the \"${STAGE_NAME}\" stage: ${e}"
          throw e
        } finally {
           echo "Build finished!"
           deleteDir()
           dir("${workspace}@tmp") {
             deleteDir()
           }
           dir("${workspace}@script") {
             deleteDir()
           }
        }
      } // end of node('edmc-master')
    } // end of stage "Publish"
  } // end of ansiColor('xterm')
}

