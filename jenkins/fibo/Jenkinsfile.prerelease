#!/usr/bin/env groovy
//
// The main Jenkinsfile for FIBO, defining the Build/Publish/Test/Deploy process that is
// executed for each push into the repository.
//
// Note that this file is in the so called "Declarative Pipeline" syntax
//
// See https://jenkins.io/doc/book/pipeline/jenkinsfile/
//
// Required plugins:
// - [Pipeline: SCM Step](https://plugins.jenkins.io/workflow-scm-step/) = workflow-scm-step
// - [Pipeline Utility Steps](https://plugins.jenkins.io/pipeline-utility-steps/) = pipeline-utility-steps

import groovy.json.JsonSlurper
import groovy.transform.Field

//String[] derivedProducts = ['datadictionary', 'index', 'vocabulary']
String[] derivedProducts = ['datadictionary', 'vocabulary']

env.ONTPUB_FAMILY='fibo'
env.ONTPUB_SPEC_HOST='spec.edmcouncil.org'
env.DEV_SPEC='AboutFIBODev.rdf'
env.PROD_SPEC='AboutFIBOProd.rdf'
env.HYGIENE_TEST_PARAMETER_VALUE='edmcouncil'
//env.HYGIENE_WARN_INCONSISTENCY_SPEC_FILE_NAME="${env.DEV_SPEC}"
env.HYGIENE_ERROR_INCONSISTENCY_SPEC_FILE_NAME="${env.PROD_SPEC}"
env.CONSISTENCY_CHECK_TIMEOUT='72h'
env.ONTPUB_IS_DARK_MODE='1'
env.ONTPUB_IMAGE='edmcouncil/ontology-publisher:stable'
env.LC_ALL='en_US.UTF-8'
env.LANG='en_US.UTF-8'
env.LANGUAGE='en_US.UTF-8'

properties([
  buildDiscarder(
          logRotator(artifactDaysToKeepStr: '', artifactNumToKeepStr: '', daysToKeepStr: '', numToKeepStr: '30')
  ),
  //
  // We let each stage running on each jenkins slave / agent decide what to check out or not
  //
//  skipDefaultCheckout(),
  //
  // Skip stages once the build status has gone to UNSTABLE.
  //
//  skipStagesAfterUnstable(),
  //
  // There must be SOME limit, if it hangs or whatever then that's a bug and therefore cancel the job.
  //
//  timeout(time: 23, unit: 'HOURS'),
  //
  // Prepend all console output generated by the Pipeline run with the time at which the line was emitted
  //
  //timestamps()
//  ansiColor('xterm')
])

@Field private mainSlackMessageObject = null

def init() {
  echo "Initialising slack functions"

  mainSlackMessageObject = slackSend(
    color: "good",
    message: "Started build <${env.BUILD_URL}|Build #${env.BUILD_NUMBER}> on branch ${env.JOB_NAME}",
    botUser: false,
    baseUrl: null,
    teamDomain: 'fibo-edmc'
  )

  if (mainSlackMessageObject == null) {
    echo "ERROR: Could not initialise slack connection"
  } else {
    println ("mainSlackMessageObject: " + mainSlackMessageObject.dump())
  }
}

def send(String color, String message) {

  if (mainSlackMessageObject == null) {
    init()
    if (mainSlackMessageObject == null) {
      slackSend color: color, message: "${message} (no main message)"
      return
    }
  }

  slackSend color: color, message: message, channel: mainSlackMessageObject.threadId, botUser: true
}

def notifyStage() {

  String buildResult = currentBuild.currentResult

  def message="Stage \"${STAGE_NAME}\" finished with status ${buildResult} in <${env.BUILD_URL}|Build #${env.BUILD_NUMBER}> on branch ${env.JOB_NAME}"

  if (buildResult == "SUCCESS") {
    echo "${message}"
    send("good", message)
  }
  else if (buildResult == "FAILURE") {
    echo "ERROR: ${message}"
    send("danger", message)
  }
  else if (buildResult == "UNSTABLE") {
    echo "WARNING: ${message}"
    send("warning", message)
  }
  else {
    echo "ERROR: ${message}"
    send("danger", message)
  }
}

//
// Return a stage object that will get executed in the appropriate ontology-publisher container
//
def runInOntologyPublisherContainer(Map config, Closure body) {

  assert config.shortStageName != null
  assert config.longStageName != null
  assert body != null

  return {
    stage(config.longStageName) {

      echo "runInOntologyPublisherContainer shortStageName:${config.shortStageName}, longStageName:${config.longStageName}"

      def containerName = "${env.JOB_NAME}-${env.NODE_NAME}-${env.EXECUTOR_NUMBER}-${config.shortStageName}".replaceAll(/[^a-zA-Z0-9_.-]/, "_")

      node('docker') {
        echo "Running in stage \"${config.longStageName}\" now"
        sh "rm -rf input"
        unstash "input"
        sh "ls -ld input/*/*"
        sh "rm -rf output"
        if (config.unstashOutputDirs) {
          config.unstashOutputDirs.each { outputDir ->
            unstash "output-${outputDir}"
          }
        }
        if (("${config.shortStageName}" != "ontology") && ("${config.shortStageName}" != "hygiene")) {
          unstash "output-ontology"
        }
        sh "install -d output tmp"
        echo "Launching docker container ${containerName}:"
        try {
          def dockerImage = docker.image(env.ONTPUB_IMAGE)
          dockerImage.pull()
          dockerImage.inside("""
            --read-only
            --name ${containerName}
            --mount type=bind,source=${env.WORKSPACE}/input,target=/input,readonly,consistency=cached
            --mount type=bind,source=${env.WORKSPACE}/output,target=/output,consistency=delegated
            --mount type=bind,source=${env.WORKSPACE}/tmp,target=/var/tmp,consistency=delegated
          """) {
            echo "Running in docker container ${containerName}"
            //
            // Now execute whatever you had in the closure
            //
            body()
          }
        } catch (e) {
          currentBuild.result = "FAILURE"
          echo "Failed stage \"${config.longStageName}\": ${e}"
          throw e
        } finally {
          echo "Finished stage \"${config.longStageName}\" in docker container ${containerName}"
          def files = findFiles(glob: "output/${env.ONTPUB_FAMILY}/**/consistency-check.json")
          if (("${config.shortStageName}" == "hygiene") && (files.length > 0)) {
            def fileContent = readFile "${files[0].path}"
            def json = new JsonSlurper().parseText(fileContent)
            for (spec_file in json?.warning?.keySet()) {
              def stat = json.warning."${spec_file}"
              catchError(buildResult: null, stageResult: 'FAILURE') {
                if (stat.containsKey('error')) {
                  error "${spec_file}: error '${stat.'error'}'"
                } else if (stat.containsKey('timeout')) {
                  error "${spec_file}: timeout after '${stat.'timeout'}'"
                } else if ((stat.containsKey('output')) && (stat.'output'.containsKey('consistent')) && !(stat.'output'.'consistent')) {
                  error "${spec_file}: is inconsistent"
                }
              }
            }
            for (spec_file in json?.error?.keySet()) {
              def stat = json.error."${spec_file}"
              if (stat.containsKey('error')) {
                error "${spec_file}: error '${stat.'error'}'"
              } else if (stat.containsKey('timeout')) {
                error "${spec_file}: timeout after '${stat.'timeout'}'"
              } else if ((stat.containsKey('output')) && (stat.'output'.containsKey('consistent')) && !(stat.'output'.'consistent')) {
                error "${spec_file}: is inconsistent"
              }
            }
          }
          if (config.archiveArtifacts == true) {
            archiveArtifacts artifacts: "output/${env.ONTPUB_FAMILY}/${config.shortStageName}/**/*.log,output/${env.ONTPUB_FAMILY}/${config.shortStageName}/**/consistency-check.json", fingerprint: true
          }
          notifyStage()
          deleteDir()
          dir("${workspace}@tmp") {
            deleteDir()
          }
        }
      }
    }
  }
}
//
// Return the stage object that runs the hygiene tests
//
def hygiene() {

  return runInOntologyPublisherContainer(
    shortStageName: 'hygiene',
    longStageName: 'Hygiene Tests',
    archiveArtifacts: true
  ) {
    sh "/publisher/publish.sh hygiene"
    stash name: "output-hygiene", includes: "output/${env.ONTPUB_FAMILY}/hygiene/**", excludes: "output/${env.ONTPUB_FAMILY}/hygiene/**/*.log"
  }
}

//
// Return the stage that produces the output of the given product
//
def product(String product) {

  return runInOntologyPublisherContainer(
    shortStageName: product,
    longStageName: "Build ${product.capitalize()}",
    archiveArtifacts: true
  ) {
    sh "/publisher/publish.sh ${product}"
    stash name: "output-${product}", includes: "output/${env.ONTPUB_FAMILY}/${product}/**", excludes: "output/${env.ONTPUB_FAMILY}/${product}/**/*.log"
  }
}

node {
  ansiColor('xterm') {
    stage('Setup') {
      dir("input/${env.ONTPUB_FAMILY}") {
        checkout scm
      }
      stash name: "input", useDefaultExcludes: false
      deleteDir()
      dir("${workspace}@tmp") {
        deleteDir()
      }
    }

    hygiene().call()

    product('ontology').call()

    stage('Build Derived Products') {
      def parallelStages = derivedProducts.collectEntries { prod ->
        [ "Build ${prod}" : product(prod)]
      }
      parallel(parallelStages)
    }
  } // end of ansiColor('xterm')
}
